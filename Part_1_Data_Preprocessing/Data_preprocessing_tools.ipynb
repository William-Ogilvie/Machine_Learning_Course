{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/William-Ogilvie/Machine_Learning_Course/blob/main/Data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "G58G2YNxtEUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"Data.csv\")\n",
        "X = dataset.iloc[:, :-1].values # iloc is index locate\n",
        "# this means all the rows and all the columns up to -1, so ignore the last column\n",
        "# which is response varaible, -1 means index of last column, range in python includes\n",
        "# lower bound but excluedes upper bound, so works, .values just means we take all the values\n",
        "y = dataset.iloc[:, -1].values # gets the response vector which is the last column\n",
        "# Or called dependent variable vector\n",
        "\n",
        "# .values extracts the data as numpy arrays rather than a pd dataframe\n"
      ],
      "metadata": {
        "id": "AvoSfHbFuKUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUJ8pUm2w93o",
        "outputId": "aa595793-48ec-4c27-9338-db9c8e14fb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZVw0e3ixBlw",
        "outputId": "2a7631a8-b62c-4ba1-adb2-96faa4455e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note the key colab commands:\n",
        "# alt b is new cell below\n",
        "# alb a is new cell above\n",
        "# alt j is move to cell below\n",
        "# alt k is move to cell above"
      ],
      "metadata": {
        "id": "7MNnXKqA1OAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have two options for missing data: remove data or replace\n",
        "# remove too many and u lose accuracy\n",
        "# common to replace with things like the average, say for salary"
      ],
      "metadata": {
        "id": "VzNqonWG1yee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') # replace missing values by the mean\n",
        "imputer.fit(X[:, 1:3]) # sets the imputer to the numeric columns and calcualtes the values, but doesn't apply\n",
        "# thats what transform does\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3]) # applys the imputer and returns the columns with\n",
        "# nan replaced by means, update X\n"
      ],
      "metadata": {
        "id": "1wlWyYyC2DpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQw7EEXkO0Xx",
        "outputId": "a084b9f3-9f19-40dc-a061-89aeb1ef33a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rather than number categorical, we do one hot encoding binary vectors for each\n",
        "# of the countries, France = (1,0, 0), Spain = (0, 1, 0), Germany = (0, 0, 1)\n",
        "# We can use numerics for binary outcomes, just don't want ordering for categorical"
      ],
      "metadata": {
        "id": "ZV48i4wUEhqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# transformers is the column u want to transformer and apply OneHotEncoder to remainder = 'passthrough' ensures we don't\n",
        "# drop the other columns\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPj79ipjFbba",
        "outputId": "4cac847a-5bb8-447b-9b5c-7f4bb849bfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "IFaKv4GCUio6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui93zEEOU40g",
        "outputId": "c76ee172-a0fd-4479-f056-562ca2ab8de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1) # so 20% in the test set\n",
        "# generally u want more in the training set than test set, random_state fixes the seed"
      ],
      "metadata": {
        "id": "79CHl6PNaSk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTwC5ybdBEl",
        "outputId": "2e40564e-17b7-4d96-ce63-20a9070ed500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEs3int0dBKj",
        "outputId": "31b6270c-bebc-4713-b5c4-b264ab8dcc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-LEzHNbdBPs",
        "outputId": "f10be09d-5a29-4b22-9982-a2dfd87b0e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ2HovJ_dBVX",
        "outputId": "9e390416-b705-40f7-ac0b-a1f4aa61cb5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In multiple linear regression, the coefficients will adjust for the features\n",
        "# magnitude\n",
        "\n",
        "# Standarisation\n",
        "# (x - \\mu) / std(x), (-3, +3) normalises\n",
        "# This works nearly all the time\n",
        "\n",
        "# Normalisation\n",
        "# x = (x - min(x)) / (max(x) - min(x))\n",
        "# Recommended when normal distribution in features\n",
        "# Obvs only take this in the x_train and x_test respectively\n",
        "\n",
        "# So is recommeneded to do standardisation\n",
        "\n",
        "# We do not need to standarise the dummy (indicator) variables, bc that makes no\n",
        "# sense\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Does standardisation\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Fit only computes mean and standard deviation, transform applies this to the\n",
        "# values\n",
        "\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:]) # ignore the one hot encoded values\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
        "\n",
        "\n",
        "# We need to apply the same transform method onto X_test, we shouldn't fit a new scalar\n",
        "# bc then our data hasn't been scaled in the same way throwing off our predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "Ahut_jF0c6r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhCHvAaUUhC_",
        "outputId": "e94f3dac-c943-4207-90dd-7bbbe51d9d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEE_oR0zVIf6",
        "outputId": "07969b6f-15b4-490c-9c48-4e39361a22ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YESUvmyAVKI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}